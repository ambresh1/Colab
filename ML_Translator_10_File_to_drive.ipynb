{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ambresh1/Colab/blob/main/ML_Translator_10_File_to_drive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKpMCGg07avi",
        "outputId": "ef12e189-4bfe-4392-cc10-75c56a2400ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/lts/1.8/cpu\n",
            "Collecting torch==1.8.2\n",
            "  Downloading https://download.pytorch.org/whl/lts/1.8/cpu/torch-1.8.2%2Bcpu-cp37-cp37m-linux_x86_64.whl (169.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 169.1 MB 54 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.2\n",
            "  Downloading https://download.pytorch.org/whl/lts/1.8/cpu/torchvision-0.9.2%2Bcpu-cp37-cp37m-linux_x86_64.whl (13.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.3 MB 38.8 MB/s \n",
            "\u001b[?25hCollecting torchaudio===0.8.2\n",
            "  Downloading https://download.pytorch.org/whl/lts/1.8/torchaudio-0.8.2-cp37-cp37m-linux_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 50.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.2) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.2) (1.21.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.2) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.12.1+cu113\n",
            "    Uninstalling torchaudio-0.12.1+cu113:\n",
            "      Successfully uninstalled torchaudio-0.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.8.2+cpu which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.2+cpu torchaudio-0.8.2 torchvision-0.9.2+cpu\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 53.6 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 40.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece\n",
        "!pip install torch==1.8.2 torchvision==0.9.2 torchaudio===0.8.2 --extra-index-url https://download.pytorch.org/whl/lts/1.8/cpu\n",
        "!pip install transformers\n",
        "!pip install python-docx\n",
        "!pip install sacremoses\n",
        "# !pip install streamlit\n",
        "!pip install nltk\n",
        "# !pip install stqdm\n",
        "!pip install requires.io\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ru274pv46oTe"
      },
      "outputs": [],
      "source": [
        "# Paragraph Translator\n",
        "from io import BytesIO\n",
        "# import gradio as gr\n",
        "# Def_04 Docx file to translated_Docx file\n",
        "#from transformers import MarianMTModel, MarianTokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import LineTokenizer\n",
        "nltk.download('punkt')\n",
        "import math\n",
        "import torch\n",
        "from docx import Document\n",
        "from time import sleep\n",
        "from tqdm import tqdm\n",
        "import docx\n",
        "import time\n",
        "from tqdm import notebook\n",
        "\n",
        "def DocxSplitting(filename):\n",
        "    doc = Document(filename)\n",
        "    fullText = []\n",
        "    for para in doc.paragraphs:\n",
        "        fullText.append(para.text)\n",
        "    # length_fullText=len(fullText)\n",
        "    return fullText\n",
        "     \n",
        "def split(list_a, chunk_size):\n",
        "\n",
        "  for i in range(0, len(list_a), chunk_size):\n",
        "    yield list_a[i:i + chunk_size]\n",
        "\n",
        "\n",
        "# mname = 'Helsinki-NLP/opus-mt-en-hi'\n",
        "# tokenizer = MarianTokenizer.from_pretrained(mname)\n",
        "# model = MarianMTModel.from_pretrained(mname)\n",
        "# model.to(device)\n",
        "#@st.cache\n",
        "def btTranslator2(Texts,num,filename):\n",
        "    if torch.cuda.is_available():  \n",
        "      dev = \"cuda\"\n",
        "    else:  \n",
        "      dev = \"cpu\" \n",
        "    device = torch.device(dev)\n",
        "    # print(device)      \n",
        "    files=Document()\n",
        "    \n",
        "    a=\"/content/drive/MyDrive/Transformers Models/Helsinki-NLP/opus-mt-en-ru\"\n",
        "    b=\"/content/drive/MyDrive/Transformers Models/Helsinki-NLP/opus-mt-ru-fr\"\n",
        "    c=\"/content/drive/MyDrive/Transformers Models/Helsinki-NLP/opus-mt-fr-en\"\n",
        "    # d=\"Helsinki-NLP/opus-mt-es-en\"\n",
        "    langs=[a,b,c]\n",
        "    # text=para\n",
        "\n",
        "    for i,lang in zip(notebook.tqdm(langs,desc=\"Book Processing... \",position=0, leave=True),langs):  \n",
        "          time.sleep(0.01)\n",
        "          # mname = '/content/drive/MyDrive/Transformers Models/opus-mt-en-hi-Trans Model'\n",
        "          tokenizer = AutoTokenizer.from_pretrained(lang)\n",
        "          model = AutoModelForSeq2SeqLM.from_pretrained(lang)\n",
        "          model.to(device)\n",
        "          lt = LineTokenizer()\n",
        "          batch_size = 64\n",
        "          \n",
        "          for i,para in zip(notebook.tqdm(Texts,desc=f\"Paras Translating...\",position=0, leave=True),Texts):\n",
        "              # para=para.text\n",
        "              # paragraphs = lt.tokenize(para)  \n",
        "              translated_paragraphs = []\n",
        "              # half_file=Document()\n",
        "              # for i,paragraph in zip(notebook.tqdm(paragraphs,desc=\"Par Translating...\",position=0, leave=True),paragraphs):\n",
        "              time.sleep(0.01)\n",
        "              sentences = sent_tokenize(para)\n",
        "              batches = math.ceil(len(sentences) / batch_size)     \n",
        "              translated = []\n",
        "              for i in range(batches):\n",
        "                  sent_batch = sentences[i*batch_size:(i+1)*batch_size]\n",
        "                  model_inputs = tokenizer(sent_batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=500).to(device)\n",
        "                  with torch.no_grad():\n",
        "                      translated_batch = model.generate(**model_inputs)\n",
        "                      translated += translated_batch\n",
        "                  translated = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
        "                  translated_paragraphs += [\" \".join(translated)]\n",
        "                  if lang[-2:]=='en':\n",
        "                    files.add_paragraph(translated)\n",
        "                  # else \n",
        "          # translated_text = \"\\n\".join(translated_paragraphs)\n",
        "          #bigtext=translated_text\n",
        "          # half_file.add_paragraph(bigtext)\n",
        "          # half_file.save(f\"/content/drive/MyDrive/Translated Books/Half_Translated/{given_name}_{lang[-5:]}_T.docx\")        \n",
        "    # files.add_paragraph(translated_text) \n",
        "    #files2save=files.save(\"Translated.docx\")\n",
        "    #files.save(\"Translated.docx\")\n",
        "    #binary_output = BytesIO()\n",
        "    #f=files.save(binary_output)\n",
        "    #f2=f.getvalue()\n",
        "    return files.save(f\"/content/drive/MyDrive/Translated Books/{filename}_{num}_Translated.docx\")\n",
        "\n",
        "\n",
        "\n",
        "chunk_size = 400 #400 paras = 10000 WORDS \n",
        "file=r\"/content/drive/MyDrive/Raw Books/01 Wife Cant Escape.docx\"\n",
        "texts=list(split(DocxSplitting(file), chunk_size))\n",
        "filename=\"01 Wife Cant Escape\"\n",
        "for i,num,words10000 in zip(notebook.tqdm(texts,desc=\"Book Divided... \",position=0, leave=True),range(len(texts)),texts):\n",
        "  # print(len(texts))\n",
        "  # if num ==0 or num ==1 or num==2 or num==3 or num==4 or num==5 :\n",
        "    # continue\n",
        "  # else:\n",
        "  if num >= 14:\n",
        "    print(f\"==============={num}\\\\{len(texts)}==============\")\n",
        "    btTranslator2(words10000,num,filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgQt31nb-FIh"
      },
      "outputs": [],
      "source": [
        "for num, text in zip(range(len(texts)), texts):\n",
        "  print(f\"========{num}==============\")\n",
        "  print(text)\n",
        "print(len(texts))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1e1d3VDvQIoP44IvlpziFpZ3nl6jiUUsd",
      "authorship_tag": "ABX9TyOwr0/fM0aQ0QwIANZagXFh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}