{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "16GwNiIm_cHolKDfpscpVI46Pygjum1ue",
      "authorship_tag": "ABX9TyPa3qsIMXMo+tQHEQh81yJi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ambresh1/Colab/blob/main/ML_Translator_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hugging Space Devlopment from file to translated file"
      ],
      "metadata": {
        "id": "66vOeEM_dhqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "!pip install torch==1.8.2 torchvision==0.9.2 torchaudio===0.8.2 --extra-index-url https://download.pytorch.org/whl/lts/1.8/cpu\n",
        "!pip install transformers ipywidgets gradio\n",
        "!pip install python-docx\n",
        "!pip install sacremoses\n"
      ],
      "metadata": {
        "id": "-kCt9qqOq9HW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90682fa6-61b8-413c-989c-9702c253cd71"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 7.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/lts/1.8/cpu\n",
            "Collecting torch==1.8.2\n",
            "  Downloading https://download.pytorch.org/whl/lts/1.8/cpu/torch-1.8.2%2Bcpu-cp37-cp37m-linux_x86_64.whl (169.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 169.1 MB 71 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.2\n",
            "  Downloading https://download.pytorch.org/whl/lts/1.8/cpu/torchvision-0.9.2%2Bcpu-cp37-cp37m-linux_x86_64.whl (13.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.3 MB 42.8 MB/s \n",
            "\u001b[?25hCollecting torchaudio===0.8.2\n",
            "  Downloading https://download.pytorch.org/whl/lts/1.8/torchaudio-0.8.2-cp37-cp37m-linux_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 52.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.2) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.2) (4.1.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.2) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.12.1+cu113\n",
            "    Uninstalling torchaudio-0.12.1+cu113:\n",
            "      Successfully uninstalled torchaudio-0.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.8.2+cpu which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.2+cpu torchaudio-0.8.2 torchvision-0.9.2+cpu\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (7.7.1)\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.4.0-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 19.7 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 27.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 57.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (3.0.3)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (7.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.3.4)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (3.6.1)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 52.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (2.0.10)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (1.15.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (5.3.1)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.11.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (23.2.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.0)\n",
            "Collecting httpx\n",
            "  Downloading httpx-0.23.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting paramiko\n",
            "  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 54.3 MB/s \n",
            "\u001b[?25hCollecting pycryptodome\n",
            "  Downloading pycryptodome-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 44.2 MB/s \n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from gradio) (3.8.1)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.18.3-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\n",
            "Collecting orjson\n",
            "  Downloading orjson-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (270 kB)\n",
            "\u001b[K     |████████████████████████████████| 270 kB 51.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from gradio) (2022.8.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.3.5)\n",
            "Collecting h11<0.13,>=0.11\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.85.0-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (from gradio) (1.9.2)\n",
            "Collecting markdown-it-py[linkify,plugins]\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "Collecting websockets\n",
            "  Downloading websockets-10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 53.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.8.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (22.1.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->gradio) (2.10)\n",
            "Collecting starlette==0.20.4\n",
            "  Downloading starlette-0.20.4-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.4 MB/s \n",
            "\u001b[?25hCollecting anyio<5,>=3.4.0\n",
            "  Downloading anyio-3.6.1-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 10.9 MB/s \n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx->gradio) (2022.6.15)\n",
            "Collecting httpcore<0.16.0,>=0.15.0\n",
            "  Downloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.1)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting mdit-py-plugins\n",
            "  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting linkify-it-py~=1.0\n",
            "  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n",
            "Collecting uc-micro-py\n",
            "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.16.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.3.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.9.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gradio) (2022.2.1)\n",
            "Collecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-4.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (594 kB)\n",
            "\u001b[K     |████████████████████████████████| 594 kB 48.6 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "  Downloading cryptography-38.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 42.7 MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[K     |████████████████████████████████| 856 kB 55.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.5->paramiko->gradio) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.5->paramiko->gradio) (2.21)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn->gradio) (7.1.2)\n",
            "Building wheels for collected packages: ffmpy, python-multipart\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4712 sha256=778549e7ea4f1f0632df170f15aea55b00fd3206b0471d15f7b388717ead81c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/e4/6c/e8059816e86796a597c6e6b0d4c880630f51a1fcfa0befd5e6\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=01901621a63ca824b040548796cc257730f7b53e51812eef8733c90937ec65c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/41/7c/bfd1c180534ffdcc0972f78c5758f89881602175d48a8bcd2c\n",
            "Successfully built ffmpy python-multipart\n",
            "Installing collected packages: jedi, sniffio, mdurl, uc-micro-py, rfc3986, markdown-it-py, h11, anyio, starlette, pynacl, mdit-py-plugins, linkify-it-py, httpcore, cryptography, bcrypt, websockets, uvicorn, tokenizers, python-multipart, pydub, pycryptodome, paramiko, orjson, huggingface-hub, httpx, ffmpy, fastapi, transformers, gradio\n",
            "Successfully installed anyio-3.6.1 bcrypt-4.0.0 cryptography-38.0.1 fastapi-0.85.0 ffmpy-0.3.0 gradio-3.4.0 h11-0.12.0 httpcore-0.15.0 httpx-0.23.0 huggingface-hub-0.10.0 jedi-0.18.1 linkify-it-py-1.0.3 markdown-it-py-2.1.0 mdit-py-plugins-0.3.1 mdurl-0.1.2 orjson-3.8.0 paramiko-2.11.0 pycryptodome-3.15.0 pydub-0.25.1 pynacl-1.5.0 python-multipart-0.0.5 rfc3986-1.5.0 sniffio-1.3.0 starlette-0.20.4 tokenizers-0.12.1 transformers-4.22.2 uc-micro-py-1.0.1 uvicorn-0.18.3 websockets-10.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from python-docx) (4.9.1)\n",
            "Building wheels for collected packages: python-docx\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184507 sha256=28e007224c66eb353e49764dd24b9807319a7f45b2ddeb414a30401dfd494276\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "Successfully built python-docx\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-0.8.11\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2022.6.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.64.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=6a44c9cf92ecde6a466f815e25db2d42f34da5cf7f6e71ee2a59792616b5c494\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "2qNBqC71q6ut"
      },
      "outputs": [],
      "source": [
        "from transformers import MarianTokenizer, MarianMTModel\n",
        "\n",
        "def newtranslate(sample_text):\n",
        "  # print(sample_text)\n",
        "  # sample_text=str(sample_text)\n",
        "  #Eng To Rus\n",
        "  source_file=\"/content/drive/MyDrive/Transformers Models/Helsinki-NLP/opus-mt-en-ru\"\n",
        "  model_en_ru = MarianMTModel.from_pretrained(source_file)\n",
        "  tokenizer_en_ru = MarianTokenizer.from_pretrained(source_file)\n",
        "  batch = tokenizer_en_ru(sample_text, return_tensors=\"pt\")\n",
        "  # print(batch)\n",
        "  generated_ids = model_en_ru.generate(**batch, max_new_tokens=2000,) # max_new_tokens=1000\n",
        "  output_1=tokenizer_en_ru.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "  # print(output_1) # prints Eng To Rus \n",
        "  \n",
        "  #Rus To Eng\n",
        "  source_file=\"/content/drive/MyDrive/Transformers Models/Helsinki-NLP/opus-mt-ru-en\"\n",
        "  model_ru_en = MarianMTModel.from_pretrained(source_file)\n",
        "  tokenizer_ru_en = MarianTokenizer.from_pretrained(source_file)\n",
        "  batch = tokenizer_ru_en(output_1, return_tensors=\"pt\")\n",
        "  # print(batch)\n",
        "  generated_ids = model_ru_en.generate(**batch, max_new_tokens=2000) #max_new_tokens=1000\n",
        "  output=tokenizer_ru_en.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "  # return output # prints Rus To Eng  \n",
        "  print(output)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize \n",
        "# import dox as dc \n",
        "# nltk.download('punkt')\n",
        "bt=''' \n",
        "Thinking back, she often participated in a lot of storytelling at school. Acting was definitely a piece of cake for her. \n",
        "\n",
        "\"Ssss, ahhh! My head is hurting so badly. Aiya! Who are you? Why can't I remember? And, who am I?\"\n",
        "\"Xiao Yao Zi, what happened? I'm Xiao Mu Zi! Don't scare me!\"\n",
        "Seeing Le Yao Yao's pained expression, Xiao Mu Zi was extremely concerned. His eyes showed that he was anxious and worried. It made Le Yao Yao feel a bit guilty.\n",
        "After all, this person truly cared about her and she was lying to him.\n",
        "But she was only half lying. She honestly had no idea whose body she was in, so she had to pretend she lost her memory. Plus, currently she did have a headache.\n",
        "Earlier she looked around her surroundings and noticed she was in a remote area with a very high wall next to her. She could hear a lot of noises behind the wall. She thought about it, beyond the walls was probably the main streets. Currently, she was most likely in the backyard of a home.\n",
        "She didn't know why the previous owner was here. Also, she had a huge bump on her head and it was throbbing.\n",
        "Based on Le Yao Yao's assumptions, the previous owner was probably trying to flip herself over the wall. Clearly, the previous owner failed and fell down. And for some odd reason, her soul entered her body.\n",
        "Le Yao Yao had no clue what had happened to the previous owner. But she wanted to find out whose body this was, and she will try to stay alive for her sake.\n",
        "After all, she had transported through time. If she doesn't do some investigating, it will be very tough for her to survive here.\n",
        "While Le Yao Yao was pondering, suddenly Xiao Mu Zi's expression turned stern. He gravely asked: \"Xiao Yao Zi, you're trying to trick me, aren't you? You're just playing dumb. In reality, you haven't lost your memory, am I correct?\"\n",
        "\n",
        "'''\n",
        "file=\"/content/drive/MyDrive/Trail Doc of 2000 words.docx\"\n",
        "from docx import Document\n",
        "\n",
        "doc = Document(\"/content/drive/MyDrive/Trail Doc of 2000 words.docx\")\n",
        "\n",
        "# for a in doc.paragraphs :\n",
        "  # newtranslate(a.text)\n",
        "  # print(a.text)\n",
        "# sbt=sent_tokenize(bt)\n",
        "\n",
        "# for a in sbt :\n",
        "#   newtranslate(a)\n",
        "# print(sbt)\n",
        "# newtranslate(bt)\n",
        "import torch\n",
        "\n",
        "# position_ids = torch.stack([torch.arange(config.max_position_embeddings) for a in range(val_dataloader.batch_size)]).to(device)"
      ],
      "metadata": {
        "id": "xHo4EBSLfEek"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import LineTokenizer\n",
        "import math\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():  \n",
        "  dev = \"cuda\"\n",
        "else:  \n",
        "  dev = \"cpu\" \n",
        "device = torch.device(dev)\n",
        " \n",
        "mname = '/content/drive/MyDrive/Transformers Models/opus-mt-en-hi-Trans Model'\n",
        "tokenizer = MarianTokenizer.from_pretrained(mname)\n",
        "model = MarianMTModel.from_pretrained(mname)\n",
        "model.to(device)\n",
        "\n",
        "lt = LineTokenizer()\n",
        "batch_size = 8\n",
        "\n",
        "text_short = ''' He was a demon! Thinking of this, Le Yao Yao became cowardly. '''\n",
        "text_long = text_short * 30\n",
        "\n",
        "paragraphs = lt.tokenize(text_long)   \n",
        "translated_paragraphs = []\n",
        "\n",
        "for paragraph in paragraphs:\n",
        "    sentences = sent_tokenize(paragraph)\n",
        "    batches = math.ceil(len(sentences) / batch_size)     \n",
        "    translated = []\n",
        "    for i in range(batches):\n",
        "        sent_batch = sentences[i*batch_size:(i+1)*batch_size]\n",
        "        model_inputs = tokenizer(sent_batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=500).to(device)\n",
        "        with torch.no_grad():\n",
        "            translated_batch = model.generate(**model_inputs)\n",
        "        translated += translated_batch\n",
        "    translated = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
        "    translated_paragraphs += [\" \".join(translated)]\n",
        "\n",
        "translated_text = \"\\n\".join(translated_paragraphs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSZX25x6Am1c",
        "outputId": "33893b2f-0cc0-4195-be72-4f6e18666de0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1232: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 512 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(translated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9xo6XNwBhrf",
        "outputId": "e1d8382d-dc27-4ba4-a48a-169f2b691db5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया । वह एक राक्षस था! इस बारे में सोचते हुए, ला यारो याो कायर बन गया ।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import LineTokenizer\n",
        "import math\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():  \n",
        "  dev = \"cuda\"\n",
        "else:  \n",
        "  dev = \"cpu\" \n",
        "device = torch.device(dev)\n",
        " \n",
        "mname = '/content/drive/MyDrive/Transformers Models/opus-mt-en-hi-Trans Model'\n",
        "tokenizer = MarianTokenizer.from_pretrained(mname)\n",
        "model = MarianMTModel.from_pretrained(mname)\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "def btTranslator(text_long):\n",
        "  lt = LineTokenizer()\n",
        "  batch_size = 8\n",
        "  paragraphs = lt.tokenize(text_long)   \n",
        "  translated_paragraphs = []\n",
        "\n",
        "  for paragraph in paragraphs:\n",
        "      sentences = sent_tokenize(paragraph)\n",
        "      batches = math.ceil(len(sentences) / batch_size)     \n",
        "      translated = []\n",
        "      for i in range(batches):\n",
        "          sent_batch = sentences[i*batch_size:(i+1)*batch_size]\n",
        "          model_inputs = tokenizer(sent_batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=500).to(device)\n",
        "          with torch.no_grad():\n",
        "              translated_batch = model.generate(**model_inputs)\n",
        "          translated += translated_batch\n",
        "      translated = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
        "      translated_paragraphs += [\" \".join(translated)]\n",
        "\n",
        "  # translated_text = \"\\n\".join(translated_paragraphs)\n",
        "  \n",
        "  return translated_paragraphs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "_1RzQ1qcCfV1",
        "outputId": "54b72940-730c-4e70-8748-91b4a94e1d61"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b4a532e9ff15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMarianMTModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMarianTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLineTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "btTranslator(bt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSTeid83CuK5",
        "outputId": "bcd5549a-85cd-4bd5-88bd-360003fb1ca5"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1232: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 512 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('वह सोचने लगी कि स्कूल में हुई कहानी की बहुत - सी बातों में हिस्सा ले रही है । निश्चित रूप से उसके लिए केक का एक टुकड़ा था.\\n\"Sssss, आह! मेरे सिर बहुत बुरी तरह से चोट लगी है. आइया! तुम कौन हो? मुझे क्यों याद नहीं है? और, मैं कौन हूँ?\\n\"xiao यारो Zi, क्या हुआ? मैं बोएओ मा Zi हूँ! मुझे डराने मत करो!\\nलेओ यारो के शोक की अभिव्यक्\\u200dति को देखने पर, जया माओ ज़ियो अति चिन्तित था । उसकी आँखों ने दिखाया कि वह चिन्तित और चिन्तित था । यह लेओ यारो थोड़ा दोषी लग रहा है.\\nआख़िरकार, इस व्यक्\\u200dति ने उसकी सच्ची परवाह की और वह उससे झूठ बोल रही थी ।\\nलेकिन वह केवल आधा झूठ बोल रही थी । उसने ईमानदारी से यह नहीं सोचा था कि वह किस का शरीर अंदर थी, इसलिए उसे अपनी याददाश्\\u200dत खोनी पड़ी । इसके अलावा, वर्तमान में वह एक सिरदर्द था.\\nइससे पहले उसने अपने आस - पास देखा और देखा कि वह एक दूर - दराज़ इलाके में रहती है, जहाँ उसके पास एक बहुत ही ऊँची दीवार थी । वह दीवार के पीछे शोर का एक बहुत सुन सकता है. उसने इसके बारे में सोचा, दीवारों के बाहर संभवतः मुख्य सड़कें थीं । फिलहाल, वह एक घर के आँगन में सबसे ज़्यादा थी ।\\nवह नहीं जानता था क्यों पिछले मालिक यहाँ था। इसके अलावा, उसके सिर पर एक बड़ी दरार थी और वह सिर हिला रही थी ।\\nयारो याओ के विचारों पर आधारित, पिछले मालिक संभवतः दीवार पर अपने आप को लाने की कोशिश कर रहा था. इससे साफ पता चलता है कि पिछले मालिक ने हार मान ली और गिर गया । और एक अजीब कारण के लिए, उसका प्राण उसके शरीर में आ गया ।\\nले यारो को पता नहीं था कि पिछले मालिक के साथ क्या हुआ था. लेकिन वह पता लगाना चाहती थी कि यह शरीर कौन था, और वह अपने कारण जीवित रहने की कोशिश करेगी ।\\nआखिरकार, उसे कुछ वक्\\u200dत के लिए ले जाया गया था । अगर वह कुछ तलाश नहीं करता है, यह उसके लिए यहाँ रहने के लिए बहुत मुश्किल होगा.\\nजब लेओ यारो सोच रहा था, अचानक जया मामू की अभिव्यक्\\u200dति कठोर हो गई। उन्होंने गंभीर रूप से पूछा: \"Xiai Yo Yi, आप मुझे धोखा देने की कोशिश कर रहे हैं, है न? तुम बस बेवकूफ खेल रहे हैं. वास्तव में, आप अपनी स्मृति खो नहीं है, मैं सही हूँ?',\n",
              " ['वह सोचने लगी कि स्कूल में हुई कहानी की बहुत - सी बातों में हिस्सा ले रही है । निश्चित रूप से उसके लिए केक का एक टुकड़ा था.',\n",
              "  '\"Sssss, आह! मेरे सिर बहुत बुरी तरह से चोट लगी है. आइया! तुम कौन हो? मुझे क्यों याद नहीं है? और, मैं कौन हूँ?',\n",
              "  '\"xiao यारो Zi, क्या हुआ? मैं बोएओ मा Zi हूँ! मुझे डराने मत करो!',\n",
              "  'लेओ यारो के शोक की अभिव्यक्\\u200dति को देखने पर, जया माओ ज़ियो अति चिन्तित था । उसकी आँखों ने दिखाया कि वह चिन्तित और चिन्तित था । यह लेओ यारो थोड़ा दोषी लग रहा है.',\n",
              "  'आख़िरकार, इस व्यक्\\u200dति ने उसकी सच्ची परवाह की और वह उससे झूठ बोल रही थी ।',\n",
              "  'लेकिन वह केवल आधा झूठ बोल रही थी । उसने ईमानदारी से यह नहीं सोचा था कि वह किस का शरीर अंदर थी, इसलिए उसे अपनी याददाश्\\u200dत खोनी पड़ी । इसके अलावा, वर्तमान में वह एक सिरदर्द था.',\n",
              "  'इससे पहले उसने अपने आस - पास देखा और देखा कि वह एक दूर - दराज़ इलाके में रहती है, जहाँ उसके पास एक बहुत ही ऊँची दीवार थी । वह दीवार के पीछे शोर का एक बहुत सुन सकता है. उसने इसके बारे में सोचा, दीवारों के बाहर संभवतः मुख्य सड़कें थीं । फिलहाल, वह एक घर के आँगन में सबसे ज़्यादा थी ।',\n",
              "  'वह नहीं जानता था क्यों पिछले मालिक यहाँ था। इसके अलावा, उसके सिर पर एक बड़ी दरार थी और वह सिर हिला रही थी ।',\n",
              "  'यारो याओ के विचारों पर आधारित, पिछले मालिक संभवतः दीवार पर अपने आप को लाने की कोशिश कर रहा था. इससे साफ पता चलता है कि पिछले मालिक ने हार मान ली और गिर गया । और एक अजीब कारण के लिए, उसका प्राण उसके शरीर में आ गया ।',\n",
              "  'ले यारो को पता नहीं था कि पिछले मालिक के साथ क्या हुआ था. लेकिन वह पता लगाना चाहती थी कि यह शरीर कौन था, और वह अपने कारण जीवित रहने की कोशिश करेगी ।',\n",
              "  'आखिरकार, उसे कुछ वक्\\u200dत के लिए ले जाया गया था । अगर वह कुछ तलाश नहीं करता है, यह उसके लिए यहाँ रहने के लिए बहुत मुश्किल होगा.',\n",
              "  'जब लेओ यारो सोच रहा था, अचानक जया मामू की अभिव्यक्\\u200dति कठोर हो गई। उन्होंने गंभीर रूप से पूछा: \"Xiai Yo Yi, आप मुझे धोखा देने की कोशिश कर रहे हैं, है न? तुम बस बेवकूफ खेल रहे हैं. वास्तव में, आप अपनी स्मृति खो नहीं है, मैं सही हूँ?'])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Def_03 text to docx file \n",
        "\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import LineTokenizer\n",
        "nltk.download('punkt')\n",
        "import math\n",
        "import torch\n",
        "from docx import Document\n",
        "\n",
        "if torch.cuda.is_available():  \n",
        "  dev = \"cuda\"\n",
        "else:  \n",
        "  dev = \"cpu\" \n",
        "device = torch.device(dev)\n",
        " \n",
        "mname = '/content/drive/MyDrive/Transformers Models/opus-mt-en-hi-Trans Model'\n",
        "tokenizer = MarianTokenizer.from_pretrained(mname)\n",
        "model = MarianMTModel.from_pretrained(mname)\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "def btTranslator(text_long):\n",
        "  files=Document()\n",
        "  lt = LineTokenizer()\n",
        "  batch_size = 8\n",
        "  paragraphs = lt.tokenize(text_long)   \n",
        "  translated_paragraphs = []\n",
        "\n",
        "  for paragraph in paragraphs:\n",
        "      sentences = sent_tokenize(paragraph)\n",
        "      batches = math.ceil(len(sentences) / batch_size)     \n",
        "      translated = []\n",
        "      for i in range(batches):\n",
        "          sent_batch = sentences[i*batch_size:(i+1)*batch_size]\n",
        "          model_inputs = tokenizer(sent_batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=500).to(device)\n",
        "          with torch.no_grad():\n",
        "              translated_batch = model.generate(**model_inputs)\n",
        "          translated += translated_batch\n",
        "      translated = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
        "      translated_paragraphs += [\" \".join(translated)]\n",
        "      files.add_paragraph(translated)\n",
        "  # translated_text = \"\\n\".join(translated_paragraphs)\n",
        "  \n",
        "  files.save('New_File.docx')\n",
        "  return translated_paragraphs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ivp3ahXEQU0",
        "outputId": "980218bb-71a2-4c07-8af2-33a72469bca9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bt=''' \n",
        "Thinking back, she often participated in a lot of storytelling at school. Acting was definitely a piece of cake for her. \n",
        "\n",
        "\"Ssss, ahhh! My head is hurting so badly. Aiya! Who are you? Why can't I remember? And, who am I?\"\n",
        "\"Xiao Yao Zi, what happened? I'm Xiao Mu Zi! Don't scare me!\"\n",
        "Seeing Le Yao Yao's pained expression, Xiao Mu Zi was extremely concerned. His eyes showed that he was anxious and worried. It made Le Yao Yao feel a bit guilty.\n",
        "After all, this person truly cared about her and she was lying to him.\n",
        "But she was only half lying. She honestly had no idea whose body she was in, so she had to pretend she lost her memory. Plus, currently she did have a headache.\n",
        "Earlier she looked around her surroundings and noticed she was in a remote area with a very high wall next to her. She could hear a lot of noises behind the wall. She thought about it, beyond the walls was probably the main streets. Currently, she was most likely in the backyard of a home.\n",
        "She didn't know why the previous owner was here. Also, she had a huge bump on her head and it was throbbing.\n",
        "Based on Le Yao Yao's assumptions, the previous owner was probably trying to flip herself over the wall. Clearly, the previous owner failed and fell down. And for some odd reason, her soul entered her body.\n",
        "Le Yao Yao had no clue what had happened to the previous owner. But she wanted to find out whose body this was, and she will try to stay alive for her sake.\n",
        "After all, she had transported through time. If she doesn't do some investigating, it will be very tough for her to survive here.\n",
        "While Le Yao Yao was pondering, suddenly Xiao Mu Zi's expression turned stern. He gravely asked: \"Xiao Yao Zi, you're trying to trick me, aren't you? You're just playing dumb. In reality, you haven't lost your memory, am I correct?\"\n",
        "\n",
        "'''\n",
        "\n",
        "btTranslator(bt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRc90NjyZeAo",
        "outputId": "31992a38-0344-4678-d38e-124c49aeb983"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1232: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 512 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['वह सोचने लगी कि स्कूल में हुई कहानी की बहुत - सी बातों में हिस्सा ले रही है । निश्चित रूप से उसके लिए केक का एक टुकड़ा था.',\n",
              " '\"Sssss, आह! मेरे सिर बहुत बुरी तरह से चोट लगी है. आइया! तुम कौन हो? मुझे क्यों याद नहीं है? और, मैं कौन हूँ?',\n",
              " '\"xiao यारो Zi, क्या हुआ? मैं बोएओ मा Zi हूँ! मुझे डराने मत करो!',\n",
              " 'लेओ यारो के शोक की अभिव्यक्\\u200dति को देखने पर, जया माओ ज़ियो अति चिन्तित था । उसकी आँखों ने दिखाया कि वह चिन्तित और चिन्तित था । यह लेओ यारो थोड़ा दोषी लग रहा है.',\n",
              " 'आख़िरकार, इस व्यक्\\u200dति ने उसकी सच्ची परवाह की और वह उससे झूठ बोल रही थी ।',\n",
              " 'लेकिन वह केवल आधा झूठ बोल रही थी । उसने ईमानदारी से यह नहीं सोचा था कि वह किस का शरीर अंदर थी, इसलिए उसे अपनी याददाश्\\u200dत खोनी पड़ी । इसके अलावा, वर्तमान में वह एक सिरदर्द था.',\n",
              " 'इससे पहले उसने अपने आस - पास देखा और देखा कि वह एक दूर - दराज़ इलाके में रहती है, जहाँ उसके पास एक बहुत ही ऊँची दीवार थी । वह दीवार के पीछे शोर का एक बहुत सुन सकता है. उसने इसके बारे में सोचा, दीवारों के बाहर संभवतः मुख्य सड़कें थीं । फिलहाल, वह एक घर के आँगन में सबसे ज़्यादा थी ।',\n",
              " 'वह नहीं जानता था क्यों पिछले मालिक यहाँ था। इसके अलावा, उसके सिर पर एक बड़ी दरार थी और वह सिर हिला रही थी ।',\n",
              " 'यारो याओ के विचारों पर आधारित, पिछले मालिक संभवतः दीवार पर अपने आप को लाने की कोशिश कर रहा था. इससे साफ पता चलता है कि पिछले मालिक ने हार मान ली और गिर गया । और एक अजीब कारण के लिए, उसका प्राण उसके शरीर में आ गया ।',\n",
              " 'ले यारो को पता नहीं था कि पिछले मालिक के साथ क्या हुआ था. लेकिन वह पता लगाना चाहती थी कि यह शरीर कौन था, और वह अपने कारण जीवित रहने की कोशिश करेगी ।',\n",
              " 'आखिरकार, उसे कुछ वक्\\u200dत के लिए ले जाया गया था । अगर वह कुछ तलाश नहीं करता है, यह उसके लिए यहाँ रहने के लिए बहुत मुश्किल होगा.',\n",
              " 'जब लेओ यारो सोच रहा था, अचानक जया मामू की अभिव्यक्\\u200dति कठोर हो गई। उन्होंने गंभीर रूप से पूछा: \"Xiai Yo Yi, आप मुझे धोखा देने की कोशिश कर रहे हैं, है न? तुम बस बेवकूफ खेल रहे हैं. वास्तव में, आप अपनी स्मृति खो नहीं है, मैं सही हूँ?']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import docx\n",
        "def getText(filename):\n",
        "    doc = docx.Document(filename)\n",
        "    fullText = []\n",
        "    for para in doc.paragraphs:\n",
        "        fullText.append(para.text)\n",
        "    return '\\n'.join(fullText)"
      ],
      "metadata": {
        "id": "YXwBqTP2FPtq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Def_04 Docx file to translated_Docx file\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import LineTokenizer\n",
        "nltk.download('punkt')\n",
        "import math\n",
        "import torch\n",
        "from docx import Document\n",
        "\n",
        "if torch.cuda.is_available():  \n",
        "  dev = \"cuda\"\n",
        "else:  \n",
        "  dev = \"cpu\" \n",
        "device = torch.device(dev)\n",
        " \n",
        "mname = '/content/drive/MyDrive/Transformers Models/opus-mt-en-hi-Trans Model'\n",
        "tokenizer = MarianTokenizer.from_pretrained(mname)\n",
        "model = MarianMTModel.from_pretrained(mname)\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "def btTranslator(docxfile):\n",
        "  a=getText(docxfile)\n",
        "  a1=a.split('\\n')\n",
        "  bigtext='''  '''\n",
        "  for a in a1:\n",
        "    bigtext=bigtext+'\\n'+a\n",
        "  files=Document()\n",
        "  lt = LineTokenizer()\n",
        "  batch_size = 8\n",
        "  paragraphs = lt.tokenize(bigtext)   \n",
        "  translated_paragraphs = []\n",
        "\n",
        "  for paragraph in paragraphs:\n",
        "      sentences = sent_tokenize(paragraph)\n",
        "      batches = math.ceil(len(sentences) / batch_size)     \n",
        "      translated = []\n",
        "      for i in range(batches):\n",
        "          sent_batch = sentences[i*batch_size:(i+1)*batch_size]\n",
        "          model_inputs = tokenizer(sent_batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=500).to(device)\n",
        "          with torch.no_grad():\n",
        "              translated_batch = model.generate(**model_inputs)\n",
        "          translated += translated_batch\n",
        "      translated = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
        "      translated_paragraphs += [\" \".join(translated)]\n",
        "      files.add_paragraph(translated)\n",
        "  # translated_text = \"\\n\".join(translated_paragraphs)\n",
        "  \n",
        "  files.save('New_File.docx')\n",
        "  return translated_paragraphs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdjc6mbSdgDL",
        "outputId": "20e9d9dc-5d4d-44fc-9dc0-9ba2b4795921"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "btTranslator(\"/content/drive/MyDrive/13 Gu Family's Wife.docx\")\n",
        "# a1=a.split('\\n')\n",
        "# # print(a1)\n",
        "# bigtext='''    '''\n",
        "# for a in a1:\n",
        "#   # print(a)\n",
        "#   bigtext=bigtext +' \\n '+a\n",
        "\n",
        "# print(bigtext)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s29aM7dlFRMZ",
        "outputId": "ca2e6f59-2d33-40d4-c499-b79dc26f16e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1232: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 512 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bAEBVjfGFqY1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}